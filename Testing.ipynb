{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event sizes:  [3175, 7333, 3280, 790, 750, 479, 1267, 2399, 269, 464, 187, 543, 580, 272, 1027, 377, 286, 391, 997, 269, 907, 272, 287, 351, 131, 333, 275, 503, 1067, 135, 691, 225, 123, 241, 263, 108, 140, 70, 239, 365, 172, 79, 244, 68, 68, 54, 69, 172, 172, 165]\n",
      "Setup time: 10 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import documents as docs\n",
    "import textcomparisons as tc\n",
    "import random\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data_folder = \"data\"\n",
    "article_files = [\"articles2019-06-01_\" + str(i) + \"-\" + str(i + 5000) + \".csv\" for i in range(0, 100000, 5000)]\n",
    "article_files = article_files + [\"articles2019-06-01_100000-100755.csv\"]\n",
    "\n",
    "def readArticles(path):\n",
    "    \"\"\" Reads df of articles from the given path, and adds a column\n",
    "    to store the Document-processed article \"\"\"\n",
    "    article_df = pd.read_csv(path)\n",
    "    article_df[\"doc\"] = None\n",
    "    return article_df\n",
    "\n",
    "# \"login\", \n",
    "keywords = [\"subscription\", \"subscribe\", \"full access\", \"digital access\", \"sign up\", \"unlimited access\", \"unlimited digital access\", \"log in\", \"sign up\"]\n",
    "def keywordsin(str):\n",
    "    for word in keywords:\n",
    "        if word in str:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def isPaywall(i, to_doc = True):\n",
    "    text = article_df.loc[i, \"text\"]\n",
    "    text = text.lower()\n",
    "    if len(text) < 500:\n",
    "        article_df.loc[i, \"paywall\"] += 0.5\n",
    "    if len(text) < 1000 and keywordsin(text):\n",
    "        article_df.loc[i, \"paywall\"] += 1\n",
    "    if to_doc and article_df.loc[i, \"doc\"] is None:\n",
    "        article_df.loc[i, \"doc\"] = docs.Document(text, clean = False)\n",
    "    return article_df.loc[i, \"paywall\"] > 0\n",
    "\n",
    "def dict_by_ids(df, ids):\n",
    "    \"\"\" Given a dataframe of articles and a list of article ids, \n",
    "    returns a dictionary with ids as keys and Documents as items, \n",
    "    computing and storing the Documents back in the df as needed\n",
    "    \"\"\"\n",
    "    doc_dict = {}\n",
    "    for doc_id in ids:\n",
    "        row = df[\"id\"] == doc_id\n",
    "        doc = df.loc[row, \"doc\"].iloc[0]\n",
    "        if doc is None:\n",
    "            doc = docs.Document(df.loc[row, \"text\"].iloc[0], clean = False)\n",
    "            df.loc[row, \"doc\"] = doc\n",
    "        doc_dict[doc_id] = doc\n",
    "    return doc_dict\n",
    "\n",
    "def subsetmat(mat, inds):\n",
    "    ''' Returns subset matrix of symmetric matrix mat, using inds\n",
    "    '''\n",
    "    subset = np.zeros((len(inds), len(inds)))\n",
    "    for i in range(len(inds)):\n",
    "        for j in range(len(inds)):\n",
    "            subset[i, j] = mat[inds[i], inds[j]]\n",
    "    return subset\n",
    "\n",
    "try:\n",
    "    article_df = pd.read_pickle(\"article_df_20190601\")\n",
    "except:\n",
    "    article_df = [readArticles(os.path.join(data_folder, file)) for file in article_files]\n",
    "    article_df = pd.concat(article_df)\n",
    "    article_df = article_df.reset_index(drop = True)\n",
    "\n",
    "    article_df[\"paywall\"] = 0\n",
    "\n",
    "events = [event for event in np.unique(article_df[\"event\"]) if not np.isnan(event)]\n",
    "n = [len(article_df.loc[article_df[\"event\"] == event]) for event in events]\n",
    "print(\"Event sizes: \", n)\n",
    "\n",
    "try:\n",
    "    results_df = pd.read_csv(\"results_20190601_clusters_temp.csv\")\n",
    "except: \n",
    "    results_df = pd.DataFrame(list(zip(events, n)), columns = [\"event\", \"n\"])\n",
    "    results_df[\"unique25\"] = np.nan\n",
    "    results_df[\"unique75\"] = np.nan\n",
    "    results_df[\"n_good\"] = np.nan\n",
    "    results_df[\"unique25_good\"] = np.nan\n",
    "    results_df[\"unique75_good\"] = np.nan\n",
    "\n",
    "ac = tc.ArticleComparisons(thresh_jaccard = .5, thresh_same_sent = .9, thresh_same_doc = .25)\n",
    "print(\"Setup time: %d seconds\" % np.round(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 23\n",
    "sample = np.array(article_df.loc[article_df[\"event\"] == events[i], \"id\"])\n",
    "article_dict = dict_by_ids(article_df, sample)\n",
    "good_inds = [i for i in range(len(sample)) if not isPaywall(sample[i])]\n",
    "results_df.loc[i, \"n_good\"] = len(good_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 351 done, 0.0 seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "clustering = ac.cluster_articles(article_dict, plot = False)\n",
    "results_df.loc[i, \"unique25\"] = ac.prop_unique_clusters(thresh_same_doc = 0.25)\n",
    "results_df.loc[i, \"unique25_good\"] = ac.prop_unique_clusters(thresh_same_doc = 0.25, inds = good_inds)\n",
    "results_df.loc[i, \"unique75\"] = ac.prop_unique_clusters(thresh_same_doc = 0.75)\n",
    "results_df.loc[i, \"unique75_good\"] = ac.prop_unique_clusters(thresh_same_doc = 0.75, inds = good_inds)\n",
    "results_df.iloc[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array([len(i.get_bow_sentences()) for i in article_dict.values()]) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(article_dict.keys())[198]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.iloc[57742, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [i for i in sample if isPaywall(i)]\n",
    "good_ids = [i for i in sample if i not in bad_ids]\n",
    "for i in bad_ids:\n",
    "    print(i, \"\\n\", article_dict[i], \"\\n\")\n",
    "ac.prop_unique_clusters(inds = bad_inds)\n",
    "# ac.display_mat(jsm_b, xlabs = bad_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_dict_good = dict_by_ids(article_df, good_ids)\n",
    "jsm = ac.jac_score_mat(article_dict_good)\n",
    "hc = ac.cluster_articles(plot = True)\n",
    "# ac.display_mat(jsm, xlabs = list(article_dict.keys()))\n",
    "n_subset = 20\n",
    "ac.display_mat(subsetmat(jsm, list(range(n_subset))), xlabs = list(article_dict_good.keys())[0:n_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = 1201\n",
    "id2 = 21618\n",
    "print(\"Good articles: %d\" % id1, id1 in good_ids, id2, id2 in good_ids)\n",
    "ac.display_mat(ac.get_match_matrix(article_dict[id1], article_dict[id2]))\n",
    "ac.print_sentence_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(article_dict[id1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in article_dict:\n",
    "    print(doc, article_dict[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tmp = pd.read_pickle(\"article_df_20190601\")\n",
    "print(time.time() - start)\n",
    "# pickle: 3.31s, csv = 26s, picke = 12.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
